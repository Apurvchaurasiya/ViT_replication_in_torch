# ViT_replication_in_torch
Vision Transformer (ViT) on MNIST  A simple implementation of a Vision Transformer applied to the MNIST handwritten digits dataset. The model splits each 28×28 image into patches, embeds them, applies Transformer encoder layers, and uses the CLS token to classify digits (0–9).
